{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy Cleaner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proposed first model.\n",
    "\n",
    "Since we would like to use other metadata for model improvement, SpaCy will not suffice.\n",
    "\n",
    "When adding metadata, a PyTorch architecture will be built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/labeled_data.csv', index_col = 0)\n",
    "data = data[['readme_content', 'Purpose']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['readme_content'] != 'Missing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>readme_content</th>\n",
       "      <th>Purpose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'&lt;h1 align=\"left\"&gt;\\n  &lt;br&gt;\\n  &lt;a href=\"http:/...</td>\n",
       "      <td>Educational; Software Development; Miscellaneo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b\"[![Python 3.6](https://img.shields.io/badge/...</td>\n",
       "      <td>Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'&lt;!-- badges: start --&gt;\\n# [geoChronR](https:...</td>\n",
       "      <td>Software development</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      readme_content  \\\n",
       "0  b'<h1 align=\"left\">\\n  <br>\\n  <a href=\"http:/...   \n",
       "1  b\"[![Python 3.6](https://img.shields.io/badge/...   \n",
       "2  b'<!-- badges: start -->\\n# [geoChronR](https:...   \n",
       "\n",
       "                                             Purpose  \n",
       "0  Educational; Software Development; Miscellaneo...  \n",
       "1                                          Analysis   \n",
       "2                              Software development   "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misc\n",
    "data['Purpose'] = data['Purpose'].str.replace('Miscellaneous - Informational link to database', 'Miscellaneous')\n",
    "data['Purpose'] = data['Purpose'].str.replace('Miscellaneous - Article referencing database links', 'Miscellaneous')\n",
    "data['Purpose'] = data['Purpose'].str.replace('Miscellaneous - Miscellaneous - Scraping database registries', 'Miscellaneous')\n",
    "data['Purpose'] = data['Purpose'].str.replace('Miscellaneous; Miscellaneous - Article referencing database links', 'Miscellaneous')\n",
    "data['Purpose'] = data['Purpose'].str.replace('Miscellaneous - Informational Link', 'Miscellaneous')\n",
    "data['Purpose'] = data['Purpose'].str.replace('Miscellaneous - Scraping database registries', 'Miscellaneous')\n",
    "\n",
    "data['Purpose'] = data['Purpose'].str.replace('Miscellaneous; Miscellaneous', 'Miscellaneous')\n",
    "data['Purpose'] = data['Purpose'].str.replace('Miscellaneous - Articles referencing database links; Miscellaneous - Scraping open science publication databases', 'Miscellaneous')\n",
    "\n",
    "data['Purpose'] = data['Purpose'].str.replace('Miscellaneous', 'Miscellaneous')\n",
    "data['Purpose'] = data['Purpose'].str.replace('Miscellaneous - Scraping database registries', 'Miscellaneous')\n",
    "\n",
    "data['Purpose'] = data['Purpose'].str.replace('Miscellaneous - Articles referencing database links', 'Miscellaneous')\n",
    "data['Purpose'] = data['Purpose'].str.replace('Miscellaneous ', 'Miscellaneous')\n",
    "data['Purpose'] = data['Purpose'].str.replace('Miscellaneous- Article with database linkts', 'Miscellaneous')\n",
    "\n",
    "\n",
    "\n",
    "# Software Dev\n",
    "data['Purpose'] = data['Purpose'].str.replace('Software development', 'Software Development')\n",
    "data['Purpose'] = data['Purpose'].str.replace('Software Development ', 'Software Development')\n",
    "data['Purpose'] = data['Purpose'].str.replace('Software Development ', 'Software Development')\n",
    "data['Purpose'] = data['Purpose'].str.replace('Storage; Software Development  ', 'Software Development')\n",
    "data['Purpose'] = data['Purpose'].str.replace('Software Development; Storage', 'Software Development')\n",
    "data['Purpose'] = data['Purpose'].str.replace('Storage; Software Development', 'Software Development')\n",
    "data['Purpose'] = data['Purpose'].str.replace('Software Development; Miscellanous - Scraping database registries', 'Software Development')\n",
    "data['Purpose'] = data['Purpose'].str.replace('Software Development; Miscellaneous', 'Software Development')\n",
    "\n",
    "# Analysis\n",
    "data['Purpose'] = data['Purpose'].str.replace('Analysis; Storage', 'Analysis')\n",
    "data['Purpose'] = data['Purpose'].str.replace('Analysis; Miscellaneous- Articles referencing databases', 'Analysis')\n",
    "data['Purpose'] = data['Purpose'].str.replace('Analysis; Educational; Miscellaneous', 'Analysis')\n",
    "data['Purpose'] = data['Purpose'].str.replace('Analysis; Educational', 'Analysis')\n",
    "data['Purpose'] = data['Purpose'].str.replace('Analysis; Software Development', 'Analysis')\n",
    "data['Purpose'] = data['Purpose'].str.replace('Analysis ', 'Analysis')\n",
    "data['Purpose'] = data['Purpose'].str.replace('Analysis; Educational', 'Analysis')\n",
    "\n",
    "# Educational\n",
    "data['Purpose'] = data['Purpose'].str.replace('Educational, Software Development', 'Educational')\n",
    "data['Purpose'] = data['Purpose'].str.replace('Educational; Miscellaneous', 'Educational')\n",
    "data['Purpose'] = data['Purpose'].str.replace('Educational', 'Educational')\n",
    "data['Purpose'] = data['Purpose'].str.replace('Educational; Miscellaneous- Informational', 'Educational')\n",
    "data['Purpose'] = data['Purpose'].str.replace('Educational; Software Development', 'Educational')\n",
    "data['Purpose'] = data['Purpose'].str.replace('Educational ', 'Educational')\n",
    "data['Purpose'] = data['Purpose'].str.replace('Educational- Informational', 'Educational')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Educational', 'Analysis', 'Software Development', 'Miscellaneous',\n",
       "       \"Can't categorize/not enough information\", 'Storage'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Purpose'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Storage                                     1\n",
       "Can't categorize/not enough information     6\n",
       "Educational                                14\n",
       "Analysis                                   15\n",
       "Software Development                       32\n",
       "Miscellaneous                              43\n",
       "Name: Purpose, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Purpose'].value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['Purpose'] != 'Storage']\n",
    "data = data[data['Purpose'] != \"Can't categorize/not enough information\"]\n",
    "data = data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>readme_content</th>\n",
       "      <th>Purpose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'&lt;h1 align=\"left\"&gt;\\n  &lt;br&gt;\\n  &lt;a href=\"http:/...</td>\n",
       "      <td>Educational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b\"[![Python 3.6](https://img.shields.io/badge/...</td>\n",
       "      <td>Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'&lt;!-- badges: start --&gt;\\n# [geoChronR](https:...</td>\n",
       "      <td>Software Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'# README for scripts and data associated wit...</td>\n",
       "      <td>Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'# Integration Tests for DesignSafe\\r\\n### Th...</td>\n",
       "      <td>Software Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>b'# nlp_ranking\\n\\nRanking universities based ...</td>\n",
       "      <td>Miscellaneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>b'# Grond\\n\\nA probabilistic earthquake source...</td>\n",
       "      <td>Software Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>b'## stat133-fall-2015\\n\\nThis repository hold...</td>\n",
       "      <td>Educational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>b'# Seismic Sound Downloader\\n\\nWebSite(En): h...</td>\n",
       "      <td>Software Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>b'# ArcticDEM Batch Download &amp; Processing Tool...</td>\n",
       "      <td>Software Development</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        readme_content               Purpose\n",
       "0    b'<h1 align=\"left\">\\n  <br>\\n  <a href=\"http:/...           Educational\n",
       "1    b\"[![Python 3.6](https://img.shields.io/badge/...              Analysis\n",
       "2    b'<!-- badges: start -->\\n# [geoChronR](https:...  Software Development\n",
       "3    b'# README for scripts and data associated wit...              Analysis\n",
       "4    b'# Integration Tests for DesignSafe\\r\\n### Th...  Software Development\n",
       "..                                                 ...                   ...\n",
       "99   b'# nlp_ranking\\n\\nRanking universities based ...         Miscellaneous\n",
       "100  b'# Grond\\n\\nA probabilistic earthquake source...  Software Development\n",
       "101  b'## stat133-fall-2015\\n\\nThis repository hold...           Educational\n",
       "102  b'# Seismic Sound Downloader\\n\\nWebSite(En): h...  Software Development\n",
       "103  b'# ArcticDEM Batch Download & Processing Tool...  Software Development\n",
       "\n",
       "[104 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Miscellaneous           43\n",
       "Software Development    32\n",
       "Analysis                15\n",
       "Educational             14\n",
       "Name: Purpose, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Purpose'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['readme_content']\n",
    "y = data['Purpose']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SpaCy Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_lg\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = string.punctuation\n",
    "\n",
    "# Create our list of stopwords\n",
    "nlp = spacy.load('en')\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "parser = English()\n",
    "\n",
    "# Creating our tokenizer function\n",
    "def spacy_tokenizer(sentence):\n",
    "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
    "    mytokens = parser(sentence)\n",
    "\n",
    "    # Lemmatizing each token and converting each token into lowercase\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "\n",
    "    # Removing stop words\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "\n",
    "    # return preprocessed list of tokens\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a Custom Transformer\n",
    "\n",
    "To further clean our text data, we’ll also want to create a custom transformer for removing initial and end spaces and converting text into lower case. Here, we will create a custom predictors class wich inherits the TransformerMixin class. This class overrides the transform, fit and get_parrams methods. We’ll also create a clean_text() function that removes spaces and converts text into lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer using spaCy\n",
    "class predictors(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        # Cleaning Text\n",
    "        return [clean_text(text) for text in X]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "# Basic function to clean the text\n",
    "def clean_text(text):\n",
    "    # Removing spaces and converting text into lowercase\n",
    "    return text.strip().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization Feature Engineering (BOW or TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vector = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(tokenizer=<function spacy_tokenizer at 0x7fdb23408dd0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vector = TfidfVectorizer(tokenizer = spacy_tokenizer)\n",
    "tfidf_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ClfSwitcher(BaseEstimator):\n",
    "    def __init__(\n",
    "        self, \n",
    "        estimator = SGDClassifier(),\n",
    "    ):\n",
    "        \"\"\"\n",
    "        A Custom BaseEstimator that can switch between classifiers.\n",
    "        :param estimator: sklearn object - The classifier\n",
    "        \"\"\" \n",
    "\n",
    "        self.estimator = estimator\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        self.estimator.fit(X, y)\n",
    "        return self\n",
    "\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        return self.estimator.predict(X)\n",
    "\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.estimator.predict_proba(X)\n",
    "\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return self.estimator.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Create pipeline using Bag of Words\n",
    "pipe = Pipeline([('cleaner', predictors()),\n",
    "                 ('vectorizer', tfidf_vector),\n",
    "                 ('clf', ClfSwitcher())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "              {\n",
    "               'clf__estimator': [SGDClassifier()], # SVM if hinge loss / logreg if log loss\n",
    "               #'tfidf__max_df': (0.25, 0.5, 0.75, 1.0),\n",
    "               #'tfidf__stop_words': ['english', None],\n",
    "               'clf__estimator__penalty': ('l2', 'elasticnet', 'l1'),\n",
    "               'clf__estimator__max_iter': [50, 80],\n",
    "               'clf__estimator__tol': [1e-4],\n",
    "               'clf__estimator__loss': ['hinge', 'log', 'modified_huber'],\n",
    "               },\n",
    "              {\n",
    "               'clf__estimator': [MultinomialNB()],\n",
    "               #'tfidf__max_df': (0.25, 0.5, 0.75, 1.0),\n",
    "               #'tfidf__stop_words': [None],\n",
    "               'clf__estimator__alpha': (1e-2, 1e-3, 1e-1),\n",
    "               },\n",
    "              {\n",
    "               'clf__estimator': [DecisionTreeClassifier()],\n",
    "               'clf__estimator__max_depth': list(range(1,20,2))}\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_grid = {'classifier__max_depth': list(range(1,20,2))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipe, param_grid, cv = 5, verbose=1, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 31 candidates, totalling 155 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 155 out of 155 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cleaner',\n",
       "                                        <__main__.predictors object at 0x7fdb26b15090>),\n",
       "                                       ('vectorizer',\n",
       "                                        TfidfVectorizer(tokenizer=<function spacy_tokenizer at 0x7fdb23408dd0>)),\n",
       "                                       ('clf', ClfSwitcher())]),\n",
       "             param_grid=[{'clf__estimator': [SGDClassifier(loss='modified_huber',\n",
       "                                                           max_iter=80,\n",
       "                                                           tol=0.0001)],\n",
       "                          'clf__estimator__loss': ['hinge', 'log',\n",
       "                                                   'modified_huber'],\n",
       "                          'clf__estimator__max_iter': [50, 80],\n",
       "                          'clf__estimator__penalty': ('l2', 'elasticnet', 'l1'),\n",
       "                          'clf__estimator__tol': [0.0001]},\n",
       "                         {'clf__estimator': [MultinomialNB()],\n",
       "                          'clf__estimator__alpha': (0.01, 0.001, 0.1)},\n",
       "                         {'clf__estimator': [DecisionTreeClassifier()],\n",
       "                          'clf__estimator__max_depth': [1, 3, 5, 7, 9, 11, 13,\n",
       "                                                        15, 17, 19]}],\n",
       "             return_train_score=True, verbose=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5676470588235294"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(grid_search).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Educational', 'Miscellaneous', 'Miscellaneous',\n",
       "       'Software Development', 'Analysis', 'Miscellaneous',\n",
       "       'Software Development', 'Miscellaneous', 'Miscellaneous',\n",
       "       'Software Development', 'Miscellaneous', 'Miscellaneous',\n",
       "       'Miscellaneous', 'Educational', 'Miscellaneous',\n",
       "       'Software Development', 'Analysis', 'Miscellaneous',\n",
       "       'Software Development', 'Software Development', 'Miscellaneous'],\n",
       "      dtype='<U20')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator Test Accuracy: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# Predicting with a test dataset\n",
    "predicted = best_estimator.predict(X_test)\n",
    "train_predicted = best_estimator.predict(X_train)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"Best Estimator Test Accuracy:\",metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator Train Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Estimator Train Accuracy:\",metrics.accuracy_score(y_train, train_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Painfully overfitting...."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
