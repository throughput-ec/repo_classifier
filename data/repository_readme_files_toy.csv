,dacat,dacat_name,cr_item,cr_name,repo_url,repo_readme,readme_content
0,Dacat1,A,110591925,feup-infolab/ontologies-database,https://github.com/feup-infolab/ontologies-database,TRUE,"bt that, given a list of ontology URIs in a `.txt` file, will attempt to downlod all those ontologies\n * A script to load those ontologies into separate graphs in a Virtuoso Instance running on `localhost`, via Virtuoso's `isql` utility. \n\n## Quickstart guide\n\nThis script is intended as a way to automatically fetch ontologies and load them into an OpenLink Virtuoso instance.\n\nFirst, clone the repo:\n\n````bash\ngit clone https://github.com/feup-infolab/ontologies-database.git\ncd ontologies-database\n````\n\nThen, run the loading script:\n\n````bash\nchmod +x ./load_ontologies_into_virtuoso.sh \n./load_ontologies_into_virtuoso.sh ontologies_list.txt\n````\n\nYour Virtuoso instance will then be loaded with all the ontologies in the `downloaded/` folder, each in its own graph.\n\n## Reloading the database\n\nOntologies can evolve, so we will periodically run the script and update this repository. If you want to refresh the ontologies in the `downloaded/` folder by yourself:\n\n- Place the updated list of ontologies in the `ontologies_list.txt` file\n- Install nvm\n    ````bash\n    curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.6/install.sh | bash\n    ````\n- Install NodeJS 8.9.0\n    ````bash\n    nvm install 8.9.0\n    ````\n\n- Activate NodeJS 8.9.0\n    ````bash\n    nvm use 8.9.0\n    ````\n\n- Run the updating script. This will attempt to re-download all ontologies in the list, if they are in `.owl` or `.rdf` format. \n    ````bash\n    npm run\n    ````\n\n## How we built the ontologies_map.txt file\n\nThe list of ontology URIs in `ontologies_list.txt` was produced by:\n\n1. Downloading the LOV dump (in `.n3`) from [here](http://lov.okfn.org/dataset/lov/sparql).\n\n2. Loading the file into Virtuoso via the Quad Store upload function (ironic name, as it support uploading nQuads, only triples... Just call it Triple Store upload, no? But I digress...) \n \n3. Running the following query in the Conductor:\n\n````sparql\nWITH <http://localhost:8890/DAV>\nSELECT ?s\nWHERE\n{\n    ?s rdf:type <http://purl.org/vocommons/voaf#Vocabulary>\n}\n```` \n"""
1,dacat1,A,41373407,nickmckay/LiPD-utilities,https://github.com/nickmckay/LiPD-utilities,TRUE,"puter.\n\n\n### extractTs\n\nExtract a time series from one or more datasets in the workspace. Your hierarchical LiPD data structure is extracted into a flattened time series structure.\n\n### collapseTs\n\nCollapse a time series back into LiPD dataset form in the workspace. Your flattened time series structure is condensed back into a hierarchical LiPD data structure\n\n### filterTs\n\nRetrieve **time series objects** that match a specific criteria. This filters out the data that you don\'t want, and returns a **new time series** of data that you do want.\n\n### queryTs\n\nRetrieve the **index numbers** of time series objects that match a specific criteria. This filters out the data that you don\'t want, and returns a list of **index numbers** of the data that you do want. \n\n------\n\n## Language-specific Documentation\n\nThe core functions are consistent across the 3 languages; However, each language has some nuances that you may be unfamiliar with. For example, in Python you may use `lipd.readLipd()`, whereas in R you use `lipd::readLipd()` or `readLipd()`. \n\nAdditionally, while the core functions remain the same, we chose to take advantage of the strengths of each language. The Python utilities have additional functions for converting and validating data. The R and Matlab utilities are better suited for data analyzation.\nThe language-specific documentation linked below will go into detail about all the functions included in each language.\n\n* [Python Docs](http://nickmckay.github.io/LiPD-utilities/python/index.html)\n\n* [R Docs](http://nickmckay.github.io/LiPD-utilities/r/index.html)\n\n* [Matlab Docs](http://nickmckay.github.io/LiPD-utilities/matlab/index.html)\n\n------\n\n## FAQ\n\n\n### What is a time series?\n\nThe LiPD dataset hierarchy is great for organization and giving context to data, but can be more difficult to sift through to find relevant information since it can often go 10+ levels deep. \n\nA time series is a flattened set of data that makes data more approachable and is used to perform data analysis. A time series is a collection of _time series objects_.\n\n**1-to-1 ratio**\n1 time series object = 1 measurement table column\n\nEach _object_ within a time series is made from one column of data in a **measurement** table. It\'s important to note that this only pertains to measurement table data. All model data (ensemble, distribution, summary) are not included when creating a time series. \n\n**Example 1: One dataset**\n\n - ODP1098B13\n\t- 1 measurement table\n\t\t- 5 columns\n\t\t\t- depth,  depth1,  SST,  TEX86,  age\n\n`extractTs` creates a time series (`ts`) of **5** objects\n\n**Example 2: Multiple datasets**\n\n - `ODP1098B13`\n\t- 1 measurement table\n\t\t- 5 columns\n\t\t\t- depth,  depth1,  SST,  TEX86,  age\n\t\t\t\n - `Ant-CoastalDML.Thamban.2006`\n\t- 1 measurement table\n\t\t- 2 columns\n\t\t\t- d18O, year\n\n - `CO00COKY`\n\t- 1 measurement table\n\t\t- 2 columns\n\t\t\t- d18O, year\n\t\t\t\n`extractTs` creates a time series (`ts`) of **9** objects\n\n\n------\n\n\n## How to Cite this code\n\n  <a href=""http://doi.org/10.5281/zenodo.60813""><img src=""https://zenodo.org/badge/24036/nickmckay/LiPD-utilities.svg""></a>\n\nUse this link to visit the Zenodo website. It provides citation information in many popular formats.\n\n------\n\n## Further information\n\n[Github - GeoChronR](https://github.com/nickmckay/GeoChronR)\n\n[Linked Earth Wiki](http://wiki.linked.earth/Main_Page)\n\n[LiPD.net](http://www.lipd.net)\n\n------\n\n## Contact\n\nIf you are having issues, please let me know at [heiser@nau.edu](mailto:heiser@nau.edu).\n\n\n------\n\n\n## License\n\nThe project is licensed under the [GNU Public License](https://github.com/nickmckay/LiPD-utilities/blob/master/Python/LICENSE).\n\n![footer NSF](assets/logo_nsf.png)\n'"
2,dacat2,B,61573112,cyber4paleo/ClimateLife,https://github.com/cyber4paleo/ClimateLife,TRUE,b'# ClimateLife\nWe aim to foster a closer interaction paleoclimate and paleoecology
278,dacat2,B,69163286,PeterHaro/peterharo.github.io,https://github.com/PeterHaro/peterharo.github.io,TRUE,b'# peterharo.github.io\nTest github.io web hosting\n'
279,Dacat3,C,48186664,usgs/earthquake-gps,https://github.com/usgs/earthquake-gps,TRUE,"b'# earthquake-gps\n\nUSGS GPS stations, data, photos, and logs.\n\nhttps://earthquake.usgs.gov/monitoring/gps\n'"
281,Dacat3,C,18522395,usgs/earthquake-website,https://github.com/usgs/earthquake-website,TRUE,b'THIS PROJECT HAS BEEN ARCHIVED
282,dacat1,A,37937864,usgs/shakemap,https://github.com/usgs/shakemap,TRUE,Missing
283,Dacat2,B,132488441,Azure-Samples/AzureMapsCodeSamples,https://github.com/Azure-Samples/AzureMapsCodeSamples,TRUE,"b""---\npage_type: sample\ndescription: A collection of over a hundred code samples for the Azure Maps Web SDK.\nlanguages:\n- javascript\nproducts:\n- azure\n- azure-maps\n---\n\n# Azure Maps Code Samples\n\nA collection of over a hundred code samples for the [Azure Maps](https://azure.com/maps) Web SDK.\n\n[Try it now](https://azuremapscodesamples.azurewebsites.net/)\n\n[![screenshot](Images/screenshot.png)](https://azuremapscodesamples.azurewebsites.net/)\n\nCode samples for the Government Cloud version of Azure can be found [here](https://github.com/Azure-Samples/AzureMapsGovCloudCodeSamples)\n\n## Related Projects\n\n* [Azure Maps Web SDK Open modules](https://github.com/microsoft/Maps/blob/master/AzureMaps.md#open-web-sdk-modules) - A collection of open source modules that extend the Azure Maps Web SDK.\n* [Azure Maps Web SDK Samples](https://github.com/Azure-Samples/AzureMapsCodeSamples)\n* [Azure Maps Gov Cloud Web SDK Samples](https://github.com/Azure-Samples/AzureMapsGovCloudCodeSamples)\n* [Azure Maps & Azure Active Directory Samples](https://github.com/Azure-Samples/Azure-Maps-AzureAD-Samples)\n* [List of open-source Azure Maps projects](https://github.com/microsoft/Maps/blob/master/AzureMaps.md)\n\n## Additional Resources\n\n* [Azure Maps (main site)](https://azure.com/maps)\n* [Azure Maps Documentation](https://docs.microsoft.com/azure/azure-maps/index)\n* [Azure Maps Blog](https://azure.microsoft.com/blog/topics/azure-maps/)\n* [Microsoft Q&A](https://docs.microsoft.com/en-us/answers/topics/azure-maps.html)\n* [MSDN Forums](https://social.msdn.microsoft.com/Forums/en-US/home?forum=azurelbs)\n* [Azure Maps feedback](https://feedback.azure.com/forums/909172-azure-maps)\n\n## Contributing\n\nWe welcome contributions. Feel free to submit code samples, file issues and pull requests on the repo and we'll address them as we can. \nLearn more about how you can help on our [Contribution Rules & Guidelines](CONTRIBUTING.md). \n\nYou can reach out to us anytime with questions and suggestions using our communities below:\n* [Microsoft Q&A](https://docs.microsoft.com/en-us/answers/topics/azure-maps.html)\n* [Azure Maps feedback](https://feedback.azure.com/forums/909172-azure-maps)\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). \nFor more information, see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or \ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## License\n\nMIT\n \nSee [License](LICENSE.md) for full license text.\n"""
284,dacat3,C,108928271,liquidnuker/rkPubApiList1,https://github.com/liquidnuker/rkPubApiList1,TRUE,Missing